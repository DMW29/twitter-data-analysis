---
title: "Tweet Uniqueness"
author: "Dianne Waterson"
date: "October 28, 2016"
output:
  html_document:
    theme: default
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.keep = "all")
knitr::opts_chunk$set(fig.path = "./figure/plot")
```

## Hypothesis

The expectation of Twitter Tweets within a dataset may be that a retweet is not an original post and therefore can be duplicated within the dataset. The expectation of Twitter Tweets may also be tweets not identified as a retweet will be an original tweet and therefore will not be duplicated elsewhere in the dataset. This is the hypothesis of this study.

## Housekeeping

Retweets are identified in the dataset by the presence of child 'retweet status' or 'is quote status' nodes. Tweets are uniquely identified using the text attribute that contains the tweet. The documentation describing tweet attributes is referenced here --> https://dev.twitter.com/overview/api/tweets. The non-presence of the 'retweet status' attribute in conjunction with the 'is quote status' attribute set to FALSE defines an original tweet. Unique tweets are tweets whose specific text is not duplicated within the dataset. 

## Analysis

Based upon the criteria that 'retweet status' is not present and 'is quote status' is FALSE, a tweet is defined as an 'original tweet'. Otherwise, it is defined as a 'retweet'. Based upon the criteria that the specific tweet text is undulpicated within the dataset, a tweet is defined as a 'unique tweet'. Otherwise, the tweet is defined as 'not unique'. A function is written to analyze each of thirteen datasets out of the 24 found here --> https://drive.google.com/drive/folders/0B7-RjEk83fGlYXRNcGJOY1ZjcVU. A contigency analysis is preformed to determine percentages of tweet categories. There are four tweet categories, (1) original and unique, (2) an original retweet, (3) original but duplicated, and (4) a duplicated retweet. The expectation is categories 2 and 3 do not exist.

## Summary of Findings

Congruent with the idea of 'messy data', the findings of this study is that original tweets are not always unique within a dataset and retweets are not always duplicated within a dataset. In all but three of the datasets, each of the four categories defined for this study contain tweets. Three of the datasets contain only retweets. 

Out of the ten datasets that report tweets in each of the four categories, an average `r (26.1+22.4+24.9+37.3+18.1+33.8+16.9+25.1+28.3+11.4)/10`% are duplicate original tweets, an average `r (15.0+14.3+29.6+16.4+12.1+21.6+18.8+2.5+17.4+13.0)/10`% are unique original tweets, an average `r (56+55.2+44.8+43.2+67.3+40.6+59.4+72.4+48.5+72.3)/10`% are duplicate retweets, and an average `r (3.3+5.8+0.0+5.0+4.0+2.5+3.1+0.7+8.1+2.9)/10`% are unique retweets. Unique tweets make up an average of only `r (17.9+22.4+30.3+19.5+14.6+25.6+23.7+23.2+16.3)/10`% of each dataset.

It is thought original tweets (category 2) that are not unique within a dataset can be attributed to two mechanisms. The first considers a tweeter actually posting the exact same text more that once without using any retweet options. Something like a copy and paste. The second mechanism considers the how tweets are queried from the Twitter API. It is the case that downloading tweets through the API may temporarily stop and create a backlog of tweets matching the user defined criteria. When the downloader re-engages, it plays catch-up. During catch-up phase is when it is thought duplicate tweets are downloaded.

Tweets designated as a retweet but are unique (category 3) within the dataset may be associated with timing. The extraction of tweets may begin at such a time to capture the last retweet of a particular message. 

Regardless of the causes of duplication or uniqueness, based on this analysis, it seems the best method of identifying a unique set of tweets within a particular dataset is to extract them through a comparison of the actual text. This method will result in a dataset of unique tweets that can be either original tweets or retweets.

```{r category}

## Set working directory
setwd("~/Twitter Project/Data")

## Check for required packages and install if need be.
packages<-function(x){
     x<-as.character(match.call()[[2]])
     if (!require(x,character.only=TRUE)){
          install.packages(pkgs=x,repos="http://cran.r-project.org", dependencies = TRUE)
          require(x,character.only=TRUE)
     }
}
packages(tidyjson)
packages(twitteR)
packages(RCurl)
packages(plyr)
packages(dplyr)
packages(gmodels)

## Create file list
filenames <- c("AtlantaDream052916.out",
               "WomensNIT noBOM.txt",
               "ChampionshipWeek1.out",
               "ChampionshipWeek2.out",
               "ChicagoSky052916.out",
               "ConnecticutSun052916.out",
               "DWingsHoops052916.out",
               "IndianaFever052916.out",
               "LA_Sparks052616.out",
               "MinnesotaLynx052716.out",
               "PhoenixHashtag.out",
               "SAStars052716.out",
               "WashMystics052916.out")

## Read in each file in the file list and calculate category percentages
for(i in filenames) {
     print(i)
     data <- read_json(i, format = "jsonl")
     class(data)

## Adding new columns to your data.frame is accomplished with spread_values(),
## which lets you dive into (potentially nested) JSON objects and extract 
## specific values. spread_values() takes jstring(), jnumber() or jlogical() 
## function calls as arguments in order to specify the type of the data that 
## should be captured at each desired key location. Here we are capturing the 
## tweet id, the tweet text, retweet status and quote status.
     twts <- data %>%
      spread_values(
               id <- jstring("id_str"),
               text <- jstring("text"),
               retwt_st <- jstring("retweeted_status"),
               qute_st <- jstring("is_quote_status")
      ) %>%
     tbl_df

## Change column names of data frame
     colnames(twts) <- c("doc.id", "tweet.id", "tweet", "retweet_status", "quote_status")

## Get tweets from data frame into a character vector
     st <- statusFactory$new(text = twts$tweet)
     twt <- st$getText()

## Create a list of tweets from character vector in order to determine uniqueness
## of each tweet
     ltwt <- as.list(twt)

## Gather statistics on whether a tweet is unique, original versus a retweet, 
## whether an original tweet is unique, or whether a retweet is unique using a
## contingency table. 
     twts$unique <- ifelse((!ltwt %in% ltwt[duplicated(ltwt)])==TRUE,
                      "Unique", "Not_Unique")
     twts$orig <- ifelse(is.na(twts$retweet_status) & twts$quote_status == "FALSE",
                    "Orig_Tweet", "Retweet")
     CrossTable(twts$unique,twts$orig, digits=3, max.width = 5, expected=TRUE, 
           prop.r=TRUE, prop.c=TRUE, prop.t=TRUE, prop.chisq=TRUE, 
           chisq = TRUE, fisher=FALSE, mcnemar=FALSE, resid=FALSE, 
           sresid=FALSE, asresid=FALSE, missing.include=FALSE,
           format=c("SAS","SPSS"), dnn = NULL)
}
```
